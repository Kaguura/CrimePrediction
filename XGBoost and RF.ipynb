{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category  DayOfWeek  Time  PdDistrict  Resolution           X          Y  \\\n",
      "0        36          5   630           7          11 -122.411912  37.775207   \n",
      "1        20          5   254           7          11 -122.419258  37.775146   \n",
      "2        21          5   121           3           0 -122.417813  37.757101   \n",
      "3        21          5   121           3           0 -122.417813  37.757101   \n",
      "4        21          5   121           3           0 -122.417813  37.757101   \n",
      "5        21          5    87           3          11 -122.415617  37.756414   \n",
      "6        25          5    85           7           0 -122.410042  37.781954   \n",
      "7         7          5    85           7           0 -122.410042  37.781954   \n",
      "8        17          5    19           5           0 -122.447761  37.769846   \n",
      "9        37          5    19           5           0 -122.447761  37.769846   \n",
      "\n",
      "   Day  Month  \n",
      "0   15      5  \n",
      "1   15      5  \n",
      "2   15      5  \n",
      "3   15      5  \n",
      "4   15      5  \n",
      "5   15      5  \n",
      "6   15      5  \n",
      "7   15      5  \n",
      "8   15      5  \n",
      "9   15      5  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Reading preprocessed data\n",
    "incidents = pd.read_csv(\"../sf-police-calls-for-service-and-incidents/label_encoded_xy.csv\")\n",
    "print(incidents.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36\n",
       "1    20\n",
       "2    21\n",
       "3    21\n",
       "4    21\n",
       "5    21\n",
       "6    25\n",
       "7     7\n",
       "8    17\n",
       "9    37\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There's no point in using resolution,\n",
    "# since we can't have it when predicting\n",
    "incidents.pop('Resolution')\n",
    "\n",
    "# Separating target\n",
    "y = incidents.pop('Category')\n",
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(incidents, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing data must be normalized and standardized separately to avoid peeking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "#normalizer = Normalizer()\n",
    "#X_train = normalizer.fit_transform(X_train)\n",
    "#X_test = normalizer.fit_transform(X_test)\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8863841517833149, eta=0.15507709650135765,\n",
       "       eval_metric='rmse', gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=6, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.9208624213752619, verbosity=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly assign parameters within typical range\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'verbosity': 0,\n",
    "    'eta': np.random.uniform(.05,.2),\n",
    "    'min_child_weight': np.random.randint(3,7),\n",
    "    'max_depth': np.random.randint(3,10),\n",
    "    'subsample': np.random.uniform(.5,1),\n",
    "    'colsample_bytree': np.random.uniform(.5,1),\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(**params)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3402715544971276"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of sample accuracy of 34%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.171404348096407"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test.values, pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of sample logarithmic loss of 2.17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried with Grid search cross validation, got memory leak\n",
    "\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "# Set the parameters by cross-validation\n",
    "#tuned_parameters = [{'n_estimators': [200], 'min_samples_leaf': [1, 10],\n",
    "                     #'random_state': [47], 'n_jobs': [-1]}]\n",
    "#clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=50, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=31, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The more estimaters, the more accurate the result,\n",
    "# the more min_samples_leaf, the more robust to noise.\n",
    "clf = RandomForestClassifier(n_estimators=200, min_samples_leaf=50,\n",
    "                            random_state=31, n_jobs = -1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2924775115405018"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly less accuraty than boosting, 29%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_rf = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3663331080633467"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test.values, pred_prob_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More loss than boosting, 2.37."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
